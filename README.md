# mit_machine_learn
Repositório das aulas de machine learn IFNET, será mais um arquivo de helper do que um repositório :)

#Acurácia (Accuracy):
Mede a proporção de exemplos classificados corretamente em relação ao total de exemplos. A fórmula é: Acurácia = (TP + TN) / (TP + TN + FP + FN), onde TP são verdadeiros positivos, TN são verdadeiros negativos, FP são falsos positivos e FN são falsos negativos.

#Precisão (Precision):
Mede a proporção de exemplos classificados como positivos que são realmente positivos. A fórmula é: Precisão = TP / (TP + FP), onde TP são verdadeiros positivos e FP são falsos positivos.

#Recall (Sensibilidade ou Revocação):
Mede a proporção de exemplos positivos que foram corretamente classificados como positivos. A fórmula é: Recall = TP / (TP + FN), onde TP são verdadeiros positivos e FN são falsos negativos.

#F1-Score:
O F1-Score é a média harmônica da precisão e do recall. A fórmula é: F1-Score = 2 * (Precision * Recall) / (Precision + Recall).

#Matriz de Confusão:
A matriz de confusão é uma tabela que mostra o número de verdadeiros positivos, falsos positivos, verdadeiros negativos e falsos negativos.
